{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Jasmine2.ipynb","version":"0.3.2","provenance":[{"file_id":"1QKBQxhKujQwWJuz967LQNs6P6ycd1IWS","timestamp":1547347458596},{"file_id":"11qvCzw1sG6zyGbClP3_fOu56kEmyGtVl","timestamp":1547340208323}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"35fohPFgzkKk","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import networkx as nx\n","import matplotlib.pyplot as plt\n","from google.colab import drive\n","import pickle\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","\n","drive.mount('/content/gdrive')\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"inSpg07cWH3D","colab_type":"code","colab":{}},"cell_type":"code","source":["options = { 'node_color': 'black','node_size': 100,'width': 3}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hCYaDhMHRY1t","colab_type":"code","colab":{}},"cell_type":"code","source":["#Translate sentence to a Scene\n","class Scene():\n","  #Each sentece is a temporal evolution of graphs\n","  def __init__(self):\n","    self.node_list = []\n","    self.sceneGraph = nx.DiGraph()\n","    self.temporalListofGraphs = []\n","    self.timeAlive = 0 #No concept of time (yet)\n","  \n","  def addNode(self, node):\n","    print(\"Debug: added node: \", node)\n","    self.node_list.append(node)\n","    self.sceneGraph.add_node(node)\n","    \n","  def drawGraphatTime(self, time):\n","    print(self.temporalListofGraphs)\n","    pos = nx.shell_layout(self.temporalListofGraphs[time]);\n","    nx.draw_random(self.temporalListofGraphs[time], with_labels=True)\n","    \n","  def captureMoment(self):\n","    #NOTE: Only incriment time here and no where else \n","    self.temporalListofGraphs.append(self.sceneGraph.copy())\n","    self.timeAlive = self.timeAlive + 1\n","    "],"execution_count":0,"outputs":[]},{"metadata":{"id":"33tivk0BXkxi","colab_type":"code","colab":{}},"cell_type":"code","source":["class Concept():\n","  #Each concept has a name and a series of ActionMemories\n","  def __init__(self, cName, a):\n","    self.conceptName = cName\n","    self.word_list = []\n","    self.action = a\n","    \n","  def addWordToConcept(self, w):\n","    self.word_list.append(w)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yIcMq6mAZkB4","colab_type":"code","colab":{}},"cell_type":"code","source":["class Mind():\n","  #Mind is the object that is saved and restored so contain state-less\n","  #information here\n","  def __init__(self):\n","    self.listOfConcepts = []\n","  \n","  def addConcept(self, c):\n","    self.listOfConcepts.append(c)\n","\n","class Jasmine():\n","  def __init__(self):\n","    #Recover memory\n","    self.mind = Mind()\n","    self.retriveMemories()\n","    self.mainScene = Scene()\n","    \n","  def resetMemory(self):\n","    self.mind = Mind()\n","    \n","  def saveMemories(self):\n","    with open('/content/gdrive/My Drive/memoryState.obj', 'wb') as file:\n","      pickle.dump(self.mind, file)\n","      \n","  def retriveMemories(self):\n","    with open('/content/gdrive/My Drive/memoryState.obj', 'rb') as file:\n","      self.mind = pickle.load(file)\n","      \n","  def readUserInput(self):\n","    currentInput = input(\"You: \")\n","    #Check if question or scene (./?)\n","    print(\"User input ends with: \", currentInput.endswith('.'))\n","    if currentInput.endswith('.'):\n","      self.parseSentence2Scene(currentInput)\n","  \n","  def sayThis(self, str):\n","    print(\"Jasmine: \", str)\n","    \n","  def askThis(self, str):\n","    self.sayThis(str)\n","    return input(\"You: \")\n","    \n","  def executeThis(self, concept, instanceName):\n","    if(concept.action == \"add node\"):\n","      self.mainScene.addNode(instanceName)\n","    self.mainScene.captureMoment()\n","    \n","  def parseSentence2Scene(self,currentInput):\n","    found = 0\n","    words = [word for word in word_tokenize(currentInput)]\n","    print(words)\n","    for word in words:\n","      #Search memory using your mind \n","      #if found then execute otherwise learn with human\n","      print(\"Looking for: \", word)\n","      for concept in self.mind.listOfConcepts:\n","        for wordSeen in concept.word_list:\n","          if wordSeen == word:\n","            #Word found in action memory \n","            #execute action in the mind\n","            found = 1\n","            self.executeThis(concept, word)\n","      if(found == 0):\n","        #Word not found ask human L0 question \n","        self.sayThis(\"I don't know what \" + word + \" means.\")\n","        ans = self.askThis(\"Can you teach me?\")\n","        #Add to static memory systematically \n","        if ans == \"Yes\" or ans == \"yes\":\n","          self.learnConceptWithHuman(word)\n","  \n","  def learnConceptWithHuman(self, word):\n","    ans = self.askThis(\"Do I Know the Concept?\")\n","    if ans == \"Yes\" or ans == \"yes\":\n","      #Search in concept memory and append word instance\n","      cName = self.askThis(\"What is the name of the concept?\")\n","      for concept in self.mind.listOfConcepts:\n","        if concept.conceptName == cName:\n","          concept.addWordToConcept(word)\n","        self.executeThis(concept, word)\n","    else:\n","      #create a new concept \n","      cName = self.askThis(\"What is the name of the concept?\")\n","      act = self.askThis(\"What is the action I am supposed to take?\")\n","      con = Concept(cName, act)\n","      con.addWordToConcept(word)\n","      self.mind.addConcept(con)\n","      self.executeThis(con, word)\n","      \n","   \n","    \n","  def makeSelfAware(self):\n","    self.mainScene.add_node(\"Jasmine\")\n","    self.mainScene.captureMoment()\n","    \n","    \n","    \n","    "],"execution_count":0,"outputs":[]},{"metadata":{"id":"XHshVTrQZcFd","colab_type":"code","colab":{}},"cell_type":"code","source":["j = Jasmine()\n","j.readUserInput()\n","j.saveMemories()\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zO6W1Hag2E6O","colab_type":"code","colab":{}},"cell_type":"code","source":["print(\"Nodes: \", j.mainScene.sceneGraph.nodes)\n","j.mainScene.drawGraphatTime(1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RZ4ce0iB_E0P","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":3723},"outputId":"d629e4fc-c32a-4c50-d269-07adbb07f399"},"cell_type":"code","source":["import nltk\n","nltk.download()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["NLTK Downloader\n","---------------------------------------------------------------------------\n","    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n","---------------------------------------------------------------------------\n","\n","Download which package (l=list; x=cancel)?\n","    Downloading collection 'all'\n","       | \n","       | Downloading package abc to /root/nltk_data...\n","       |   Unzipping corpora/abc.zip.\n","       | Downloading package alpino to /root/nltk_data...\n","       |   Unzipping corpora/alpino.zip.\n","       | Downloading package biocreative_ppi to /root/nltk_data...\n","       |   Unzipping corpora/biocreative_ppi.zip.\n","       | Downloading package brown to /root/nltk_data...\n","       |   Unzipping corpora/brown.zip.\n","       | Downloading package brown_tei to /root/nltk_data...\n","       |   Unzipping corpora/brown_tei.zip.\n","       | Downloading package cess_cat to /root/nltk_data...\n","       |   Unzipping corpora/cess_cat.zip.\n","       | Downloading package cess_esp to /root/nltk_data...\n","       |   Unzipping corpora/cess_esp.zip.\n","       | Downloading package chat80 to /root/nltk_data...\n","       |   Unzipping corpora/chat80.zip.\n","       | Downloading package city_database to /root/nltk_data...\n","       |   Unzipping corpora/city_database.zip.\n","       | Downloading package cmudict to /root/nltk_data...\n","       |   Unzipping corpora/cmudict.zip.\n","       | Downloading package comparative_sentences to\n","       |     /root/nltk_data...\n","       |   Unzipping corpora/comparative_sentences.zip.\n","       | Downloading package comtrans to /root/nltk_data...\n","       | Downloading package conll2000 to /root/nltk_data...\n","       |   Unzipping corpora/conll2000.zip.\n","       | Downloading package conll2002 to /root/nltk_data...\n","       |   Unzipping corpora/conll2002.zip.\n","       | Downloading package conll2007 to /root/nltk_data...\n","       | Downloading package crubadan to /root/nltk_data...\n","       |   Unzipping corpora/crubadan.zip.\n","       | Downloading package dependency_treebank to /root/nltk_data...\n","       |   Unzipping corpora/dependency_treebank.zip.\n","       | Downloading package dolch to /root/nltk_data...\n","       |   Unzipping corpora/dolch.zip.\n","       | Downloading package europarl_raw to /root/nltk_data...\n","       |   Unzipping corpora/europarl_raw.zip.\n","       | Downloading package floresta to /root/nltk_data...\n","       |   Unzipping corpora/floresta.zip.\n","       | Downloading package framenet_v15 to /root/nltk_data...\n","       |   Unzipping corpora/framenet_v15.zip.\n","       | Downloading package framenet_v17 to /root/nltk_data...\n","       |   Unzipping corpora/framenet_v17.zip.\n","       | Downloading package gazetteers to /root/nltk_data...\n","       |   Unzipping corpora/gazetteers.zip.\n","       | Downloading package genesis to /root/nltk_data...\n","       |   Unzipping corpora/genesis.zip.\n","       | Downloading package gutenberg to /root/nltk_data...\n","       |   Unzipping corpora/gutenberg.zip.\n","       | Downloading package ieer to /root/nltk_data...\n","       |   Unzipping corpora/ieer.zip.\n","       | Downloading package inaugural to /root/nltk_data...\n","       |   Unzipping corpora/inaugural.zip.\n","       | Downloading package indian to /root/nltk_data...\n","       |   Unzipping corpora/indian.zip.\n","       | Downloading package jeita to /root/nltk_data...\n","       | Downloading package kimmo to /root/nltk_data...\n","       |   Unzipping corpora/kimmo.zip.\n","       | Downloading package knbc to /root/nltk_data...\n","       | Downloading package lin_thesaurus to /root/nltk_data...\n","       |   Unzipping corpora/lin_thesaurus.zip.\n","       | Downloading package mac_morpho to /root/nltk_data...\n","       |   Unzipping corpora/mac_morpho.zip.\n","       | Downloading package machado to /root/nltk_data...\n","       | Downloading package masc_tagged to /root/nltk_data...\n","       | Downloading package moses_sample to /root/nltk_data...\n","       |   Unzipping models/moses_sample.zip.\n","       | Downloading package movie_reviews to /root/nltk_data...\n","       |   Unzipping corpora/movie_reviews.zip.\n","       | Downloading package names to /root/nltk_data...\n","       |   Unzipping corpora/names.zip.\n","       | Downloading package nombank.1.0 to /root/nltk_data...\n","       | Downloading package nps_chat to /root/nltk_data...\n","       |   Unzipping corpora/nps_chat.zip.\n","       | Downloading package omw to /root/nltk_data...\n","       |   Unzipping corpora/omw.zip.\n","       | Downloading package opinion_lexicon to /root/nltk_data...\n","       |   Unzipping corpora/opinion_lexicon.zip.\n","       | Downloading package paradigms to /root/nltk_data...\n","       |   Unzipping corpora/paradigms.zip.\n","       | Downloading package pil to /root/nltk_data...\n","       |   Unzipping corpora/pil.zip.\n","       | Downloading package pl196x to /root/nltk_data...\n","       |   Unzipping corpora/pl196x.zip.\n","       | Downloading package ppattach to /root/nltk_data...\n","       |   Unzipping corpora/ppattach.zip.\n","       | Downloading package problem_reports to /root/nltk_data...\n","       |   Unzipping corpora/problem_reports.zip.\n","       | Downloading package propbank to /root/nltk_data...\n","       | Downloading package ptb to /root/nltk_data...\n","       |   Unzipping corpora/ptb.zip.\n","       | Downloading package product_reviews_1 to /root/nltk_data...\n","       |   Unzipping corpora/product_reviews_1.zip.\n","       | Downloading package product_reviews_2 to /root/nltk_data...\n","       |   Unzipping corpora/product_reviews_2.zip.\n","       | Downloading package pros_cons to /root/nltk_data...\n","       |   Unzipping corpora/pros_cons.zip.\n","       | Downloading package qc to /root/nltk_data...\n","       |   Unzipping corpora/qc.zip.\n","       | Downloading package reuters to /root/nltk_data...\n","       | Downloading package rte to /root/nltk_data...\n","       |   Unzipping corpora/rte.zip.\n","       | Downloading package semcor to /root/nltk_data...\n","       | Downloading package senseval to /root/nltk_data...\n","       |   Unzipping corpora/senseval.zip.\n","       | Downloading package sentiwordnet to /root/nltk_data...\n","       |   Unzipping corpora/sentiwordnet.zip.\n","       | Downloading package sentence_polarity to /root/nltk_data...\n","       |   Unzipping corpora/sentence_polarity.zip.\n","       | Downloading package shakespeare to /root/nltk_data...\n","       |   Unzipping corpora/shakespeare.zip.\n","       | Downloading package sinica_treebank to /root/nltk_data...\n","       |   Unzipping corpora/sinica_treebank.zip.\n","       | Downloading package smultron to /root/nltk_data...\n","       |   Unzipping corpora/smultron.zip.\n","       | Downloading package state_union to /root/nltk_data...\n","       |   Unzipping corpora/state_union.zip.\n","       | Downloading package stopwords to /root/nltk_data...\n","       |   Unzipping corpora/stopwords.zip.\n","       | Downloading package subjectivity to /root/nltk_data...\n","       |   Unzipping corpora/subjectivity.zip.\n","       | Downloading package swadesh to /root/nltk_data...\n","       |   Unzipping corpora/swadesh.zip.\n","       | Downloading package switchboard to /root/nltk_data...\n","       |   Unzipping corpora/switchboard.zip.\n","       | Downloading package timit to /root/nltk_data...\n","       |   Unzipping corpora/timit.zip.\n","       | Downloading package toolbox to /root/nltk_data...\n","       |   Unzipping corpora/toolbox.zip.\n","       | Downloading package treebank to /root/nltk_data...\n","       |   Unzipping corpora/treebank.zip.\n","       | Downloading package twitter_samples to /root/nltk_data...\n","       |   Unzipping corpora/twitter_samples.zip.\n","       | Downloading package udhr to /root/nltk_data...\n","       |   Unzipping corpora/udhr.zip.\n","       | Downloading package udhr2 to /root/nltk_data...\n","       |   Unzipping corpora/udhr2.zip.\n","       | Downloading package unicode_samples to /root/nltk_data...\n","       |   Unzipping corpora/unicode_samples.zip.\n","       | Downloading package universal_treebanks_v20 to\n","       |     /root/nltk_data...\n","       | Downloading package verbnet to /root/nltk_data...\n","       |   Unzipping corpora/verbnet.zip.\n","       | Downloading package verbnet3 to /root/nltk_data...\n","       |   Unzipping corpora/verbnet3.zip.\n","       | Downloading package webtext to /root/nltk_data...\n","       |   Unzipping corpora/webtext.zip.\n","       | Downloading package wordnet to /root/nltk_data...\n","       |   Unzipping corpora/wordnet.zip.\n","       | Downloading package wordnet_ic to /root/nltk_data...\n","       |   Unzipping corpora/wordnet_ic.zip.\n","       | Downloading package words to /root/nltk_data...\n","       |   Unzipping corpora/words.zip.\n","       | Downloading package ycoe to /root/nltk_data...\n","       |   Unzipping corpora/ycoe.zip.\n","       | Downloading package rslp to /root/nltk_data...\n","       |   Unzipping stemmers/rslp.zip.\n","       | Downloading package maxent_treebank_pos_tagger to\n","       |     /root/nltk_data...\n","       |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n","       | Downloading package universal_tagset to /root/nltk_data...\n","       |   Unzipping taggers/universal_tagset.zip.\n","       | Downloading package maxent_ne_chunker to /root/nltk_data...\n","       |   Unzipping chunkers/maxent_ne_chunker.zip.\n","       | Downloading package punkt to /root/nltk_data...\n","       |   Unzipping tokenizers/punkt.zip.\n","       | Downloading package book_grammars to /root/nltk_data...\n","       |   Unzipping grammars/book_grammars.zip.\n","       | Downloading package sample_grammars to /root/nltk_data...\n","       |   Unzipping grammars/sample_grammars.zip.\n","       | Downloading package spanish_grammars to /root/nltk_data...\n","       |   Unzipping grammars/spanish_grammars.zip.\n","       | Downloading package basque_grammars to /root/nltk_data...\n","       |   Unzipping grammars/basque_grammars.zip.\n","       | Downloading package large_grammars to /root/nltk_data...\n","       |   Unzipping grammars/large_grammars.zip.\n","       | Downloading package tagsets to /root/nltk_data...\n","       |   Unzipping help/tagsets.zip.\n","       | Downloading package snowball_data to /root/nltk_data...\n","       | Downloading package bllip_wsj_no_aux to /root/nltk_data...\n","       |   Unzipping models/bllip_wsj_no_aux.zip.\n","       | Downloading package word2vec_sample to /root/nltk_data...\n","       |   Unzipping models/word2vec_sample.zip.\n","       | Downloading package panlex_swadesh to /root/nltk_data...\n","       | Downloading package mte_teip5 to /root/nltk_data...\n","       |   Unzipping corpora/mte_teip5.zip.\n","       | Downloading package averaged_perceptron_tagger to\n","       |     /root/nltk_data...\n","       |   Unzipping taggers/averaged_perceptron_tagger.zip.\n","       | Downloading package averaged_perceptron_tagger_ru to\n","       |     /root/nltk_data...\n","       |   Unzipping taggers/averaged_perceptron_tagger_ru.zip.\n","       | Downloading package perluniprops to /root/nltk_data...\n","       |   Unzipping misc/perluniprops.zip.\n","       | Downloading package nonbreaking_prefixes to\n","       |     /root/nltk_data...\n","       |   Unzipping corpora/nonbreaking_prefixes.zip.\n","       | Downloading package vader_lexicon to /root/nltk_data...\n","       | Downloading package porter_test to /root/nltk_data...\n","       |   Unzipping stemmers/porter_test.zip.\n","       | Downloading package wmt15_eval to /root/nltk_data...\n","       |   Unzipping models/wmt15_eval.zip.\n","       | Downloading package mwa_ppdb to /root/nltk_data...\n","       |   Unzipping misc/mwa_ppdb.zip.\n","       | \n","     Done downloading collection all\n","\n","---------------------------------------------------------------------------\n","    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n","---------------------------------------------------------------------------\n"],"name":"stdout"}]}]}